\documentclass[a4paper,11pt]{article}

\usepackage[a4paper]{geometry}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsbsy}
\usepackage{amssymb}

% URLs in citations
\usepackage[hidelinks]{hyperref}
%\usepackage{biblatex}
%\bibliography{refs}
% break at any character
%\setcounter{biburllcpenalty}{7000}
%\setcounter{biburlucpenalty}{8000}
% cool colors
% http://tex.stackexchange.com/a/847/56242
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!60!black},
    citecolor={red!60!black},
    urlcolor={red!60!black}
}

% courier font for monospace bold
\usepackage{courier}
% Libertine font
%\usepackage{libertine}
%\usepackage[libertine]{newtxmath}


% no indent and horizontal space
\usepackage[parfill]{parskip}

% nice look
\frenchspacing
\usepackage{microtype}

% tables with width
\usepackage{tabularx}

\title{Database Technology [2ID35] \\
\textbf{Project part 2}}

\author{
Michiel Fortuin --- 0812105 \\
Fengjun Wang --- 0925350 \\
Ferry Timmers --- 0637586 \\
Myrthe van Delft --- 0657742}

\date{\today}

\begin{document}
\newcommand{\papername}[0]{Clustering Streaming Graphs}

\maketitle

\section{Introduction}
As part of the database and technology course of 2014-2015, we have to investigate a research paper from the scientific community. For our project we were assigned the paper \papername \cite{paper}. This paper presents an algorithm for 'online' clustering of (large) streaming graphs. In this first progress report we will present a brief literature survey, the main outline of the results of the paper, and a rough estimate of the planning of the project. We may refer to \cite{paper} as `the paper' or `our paper'.

\section{Literature Survey}
%A brief literature survey, providing context and motivation for your paper.
In the paper, a method for clustering online, streaming graphs is presented. A streaming graph is a graph where the updates to the graph are given in the form of a \textit{stream} of edge or vertex additions or deletions. Handling of such rapidly changing graphs is challenging because of its dynamic, online nature and massive scale. An algorithm thus would necessarily need to be incremental and extremely fast, and preferably amenable to parallel or distributed implementations. 

The graph clustering problem has been a subject of extensive research, but mostly assuming an \textit{offline} setting where the entire graph is given beforehand. The paper presents an algorithm which is suitable to an online setting, and is capable of maintaining a decent graph clustering while updates are performed on the graph. 

In \cite{11} random sampling was used to solve this problem in a offline fashion. This random sampling was first used in this paper. In \cite{12} solves the same problem, but then in an online fashion, using an Erdös-Réyni model. Problem with this algorithm in \cite{12} is that it does not allow deletion or modification of the graph. Also it does not scale well with the number of clusters. The algorithm presented in  \cite{13} solves the same problem in an online fashion. This hash-compressed micro-clusters and find structurally similar graphs in a stream of large number of small graphs. In \cite{14} reservoir sampling is also used. This algorithm is called the AZY algorithm. Our paper is based on top of this algorithm. It can be seen as an extension. The AZY does not consider deletions in the graph.

In \cite{DynPar} the algorithm presented in our paper is used for analyzing social network. The weighted graph is used, which is based on the chat frequency and access recency. In \cite{StrHyp} the algorithm is adapted for use with hypergraphs. The paper \cite{ProStr} describes another clustering algorithm similar to ours, only the query's aren't about a snapshot of the graph, but deletions in the past and additions in the future are taken into account with the clustering.


\section{The paper}
The research problem is clustering large-scale and rapidly changing "streaming" graphs where the updates to a graph are given in form of a stream of vertex or edge additions and deletions. 

The algorithm in the paper is proposed to solve the clustering problem and also satisfies 3 optimization requirements:
\begin{itemize}
\item[a] it should be simple to adjust to parallelizations and distributed environments
\item[b] it should handle massive inputs, with a relatively low overall space complexity
\item[c] it should handle high throughput streams, with a relatively low time complexity per update or query
\end{itemize}

To test the algorithm, it is tested against two other clustering algorithms. The first is METIS, a standard clustering algorithm, with some slight modifications to make it suitable to an `online' environment. The second is AZY, a clustering algorithm which is suited to `online' environment, but with expected much worse performance. The tests are performed on 4 different datasets:
\begin{itemize}
\item[1] cit-HepPh, which shows a large increase in the number of vertices over time. This graph has (in total) $34k$ vertices and $420k$ edges.
\item[2] web-NotreDame. This graph has (in total) $330k$ vertices and $1.5M$ edges.
\item[3] replies, a very sparse and not well clustering graph. This graph has (in total) $1.9M$ vertices and $1.6M$ edges.
\item[4] DNS Edges, containing many duplicate edges but with different time stamps. This graph has (in total) $180k$ vertices and $4.8M$ edges.
\end{itemize}

\subsection{Results}
The performance of the algorithms is measured in two different aspects: quality and performance. Furthermore, some tuning experiments with adjusted p-values are done.

\subsubsection{Quality}
The paper tests the quality of the 4 datasets on the Structural Sampler, METIS, and AZY, with different clustering group size bounds, while fixing the sampling threshold parameter p at 1. The results show that the cut-size quality of the Structural Sampler is almost as well as METIS, which is assumed to be close to the best clustering. AZY performance significantly worse than both METIS and the Structural Sampler.

Furthermore, the paper tests the cut-size quality of the Structural Sampler, METIS, and AZY on the cit-HepPh and DNS Edges datasets, using different p-values (the sampling threshold).
For both METIS and the Structural Sampler, applying a lower sampling threshold could bring a worse clustering quality. However, the AZY is mostly uninfluenced by a lower sampling threshold. 

\subsubsection{Performance}
The paper tests the performance of both the Structural Sampler and METIS on cit-HepPh and web-NotreDame, using different ratios for the number of queries versus the number of updates. 
The throughput of the Structural Sampler out-performs METIS, increasingly so with an increasing query vs. update ratio, up to more an improvement more than 3 orders of magnitude.

Furthermore, the paper tests Structural Sampler and METIS, with different clustering size bounds B, while fixing Query/Update-ratio at 0.5, on the datasets DNS Edges and web-NotreDame.
The throughput of Structural Sampler out-performs METIS with more than 3 orders of magnitude. However, METIS has almost the same throughput for different values of the clustering size bounds B, while the performance of the Structural Sampler decreases as B increases. 

Finally, the paper tests the throughput of Structural Sampler and METIS on cit-HepPh and DNS Edges, while adjusting the p-value. 
The effect of the sampling threshold on METIS is very limited but it does give the same trend as the Structural Sampler approach. Both show that a lower sampling threshold increases performance. 

\section{Planning}
The planning of our project looks as follows. Depending on whether or not we receive the source code from the author, we will either execute with 3a (if we do receive the source code), or 3b (if we do not receive the source code).
\begin{enumerate}
\item[1] Mail the authors with a request for the source code. \textit{Completed}\item[2] Obtain the datasets used in the paper, as far as possible. \\
\textit{Completed}
\item[3-a] \textit{The authors did not wish to share their code}
\item[3-b] If we do not receive the source code from the authors in a timely manner, then:
\begin{enumerate}
\item[i] Implement the algorithm presented in the paper. \\
\textit{We currently have a working implementation, which we still wish to optimize somewhat.}
\item[ii] Compare the quality results presented in the paper with those of METIS and our implementation.\\
\textit{We are currently working on the script which will automate collecting the METIS test results.} %TODO update?
\item[iii] \textit{Expansion:} Compare the performance results presented in the paper with those of METIS and our implementation.
\end{enumerate}
\item[4] Possible expansions, depending on the time it takes to implement and run the experiments:
\begin{enumerate}
\item[i] Repeat the tests on different datasets. An interesting candidate is a dataset showing no obvious clustering. \\
\textit{We currently have a generator for datasets. Implemented options are: Euler network and graph-free network.} %TODO update?
%Euler network: graph without clusters
%scale free network: graph with clusters
%candidates are randomly generated clustering datasets, randomly generated datasets which do not show obvious clustering, significantly smaller datasets and the dataset showing the social network generated by the heroes from the Marvel Universe.
\item[ii] Testing for additional $p$-values aside from those used in the paper, and verifying the claims made about higher and/or lower $p$-values.
\item[iii] The paper claims the algorithm can be easily parallelized or run distributed. We are interested to test the method presented for parallelizing the algorithm.
\end{enumerate}
\end{enumerate}

\pagebreak
\subsection{Time Schedule}
Here, we list the dates and deadlines we set out for ourselves, to ensure successful completion of the project.

\begin{tabular}{|l|l|}
\hline
\textbf{Date}	&	\textbf{Deadline}\\
\hline
13 May	&	Finish scheduling report\\
\hline
24 May	&	Untested, but completed implementation of the algorithms\\
		&	Completed preprocessing the datasets\\
		&	Project part 3 \\
\hline
31 May	&	Completed and debugged implementation of the algorithms\\
		& 	Start testing and preliminaries of the final report\\
\hline
7 June	&	Start discussing final presentation\\
\hline
14 June	&	Finished main experiments\\
\hline
21 June	&	Finished final report (project part 4)\\
\hline
\end{tabular}

\subsection{Progress 13-05}
Currently, we have e-mailed the author and have been able to obtain three of the four datasets used in the paper. The fourth dataset is from an IBM process, and we do not believe it to be possible to gain access to this dataset. 

Furthermore, we have received a negative response from the author, and thus we will need to create our own implementation of the presented algorithm. However, we have been able to find an implementation of the METIS algorithm, and will use this implementation as a bench mark, and not write our own. 

Started on the implementation of the algorithm and the context of the algorithms.

\subsection{Progress 25-05}
At this point in time, we have finished writing the implementation of the structural sampler architecture. Our implementation reports the cutsize of the clusters at certain intervals, which is the measure of quality used for the clusters in the paper. However, the code runs quite slowly, so we still wish to optimize the code somewhat via profiling.

Furthermore, we have started integrating the code of METIS with our project. We expect this to be finished on the 25th, up to a few remaining bugs.

\subsection{Tools} 
We have decided to use git as a code repository for the project, and we will write our code in C++. The development environment we will use is Visual Studio. For writing documents and such we will use \LaTeX. We might use additional benchmarking tools. Any additional datasets we will we need, we believe to be able to find on the internet. 

\begin{thebibliography}{99}
\bibitem{paper} A. Eldawy, R. Khandekar and K. Wu, ``Clustering Streaming Graphs'', in \textit{32nd IEEE International Conference on Distributed Computing Systems}, 2012.
\bibitem{1} A. Jain and R. Dubes, ``Algorithms for Clustering Data''. Prentice-Hall, 1988.
\bibitem{11} D. Karger, ``Global Min-cuts in RNC, and Other Ramifications of a Simple Min-Cut Algorithm'', in \textit{ACM-SIAM Symposium on Discrete Algorithms}, Austin, TX, Jan. 1993, pp. 21-30.
\bibitem{12} H. Zanghi, C. Ambroise and V. Miele, ``Fast Online Graph Clustering Via Erdos-Rényi Mixture'', \textit{Pattern Recognition}, vol. 41, no. 12, pp. 3592-3599, 2008.
\bibitem{13} C. Aggarwal, Y. Zhao and P. Yu, ``On Clustering Graph Streams'', in \textit{Proceedings of the SIAM International Conference on Data Mining}, Columbos, OH, Apr. 2010.
\bibitem{14} ---,  ``Outlier Detection in Graph Streams'', in \textit{Proceedings of the Internation Conference on Data Engineering, ICDE}, Hannover, Germany, Apr. 2011, pp. 399-409.
\bibitem{METIS} G. Karypis and V. Kumar, ``A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs'', in \textit{SIAM Journal of Scientific Computing}, vol. 20, no. 1, pp. 359-392, 1998.
\bibitem{DynPar} M. Yuan, ``Dynamic Partitioning of Social Networks'', University of Illinois, Urbana, Illinois, 2012.
\bibitem{StrHyp} G. Wing, ``Streaming Hypergraph Partition for Massive Graphs'', Kent State University, Dec. 2013.
\bibitem{ProStr} m. Yuan, K. Wu, Y. Lu and G. Jacques-Silva, ``Efficient Processing of Streaming Graphs for Evolution-Aware Clustering'', in \textit{CIKM '13, Proceedings of the 22nd ACM international conference on Conference on information \& knowledge management}, pp. 319-328, New York, 2013
\end{thebibliography}

\end{document}